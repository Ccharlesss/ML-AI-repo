{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364a7e1c-f3ea-444f-b279-ea014f2fbc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------------------------------------------- PART A : Grade Prediction Model ------------------------------------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3979e93f-df6e-4994-8ce4-c9508c1d3162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/romainkuhne/.cache/kagglehub/datasets/nikhil7280/student-performance-multiple-linear-regression/versions/1\n"
     ]
    }
   ],
   "source": [
    "### 1) Download the DataSet:\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"nikhil7280/student-performance-multiple-linear-regression\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e40959e2-e77c-40e1-bf03-eab9dc1e1ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Hours Studied  Previous Scores Extracurricular Activities  Sleep Hours  \\\n",
      "0                 7               99                        Yes            9   \n",
      "1                 4               82                         No            4   \n",
      "2                 8               51                        Yes            7   \n",
      "3                 5               52                        Yes            5   \n",
      "4                 7               75                         No            8   \n",
      "...             ...              ...                        ...          ...   \n",
      "9995              1               49                        Yes            4   \n",
      "9996              7               64                        Yes            8   \n",
      "9997              6               83                        Yes            8   \n",
      "9998              9               97                        Yes            7   \n",
      "9999              7               74                         No            8   \n",
      "\n",
      "      Sample Question Papers Practiced  Performance Index  \n",
      "0                                    1               91.0  \n",
      "1                                    2               65.0  \n",
      "2                                    2               45.0  \n",
      "3                                    2               36.0  \n",
      "4                                    5               66.0  \n",
      "...                                ...                ...  \n",
      "9995                                 2               23.0  \n",
      "9996                                 5               58.0  \n",
      "9997                                 5               74.0  \n",
      "9998                                 0               95.0  \n",
      "9999                                 1               64.0  \n",
      "\n",
      "[10000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "### 2) Get the downloaded DataSet and store it into a pd.DataFrame:\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Path to dataset folder\n",
    "dataset_path = \"/Users/romainkuhne/.cache/kagglehub/datasets/nikhil7280/student-performance-multiple-linear-regression/versions/1\"\n",
    "\n",
    "# Find the CSV file (assuming only one CSV in the folder)\n",
    "for file_name in os.listdir(dataset_path):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        csv_file = os.path.join(dataset_path, file_name)\n",
    "        break\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3032ed68-1eac-437e-9cc7-52982d46b5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Hours Studied  Previous Scores  Extracurricular Activities  Sleep Hours  \\\n",
      "0                 7               99                           1            9   \n",
      "1                 4               82                           0            4   \n",
      "2                 8               51                           1            7   \n",
      "3                 5               52                           1            5   \n",
      "4                 7               75                           0            8   \n",
      "...             ...              ...                         ...          ...   \n",
      "9995              1               49                           1            4   \n",
      "9996              7               64                           1            8   \n",
      "9997              6               83                           1            8   \n",
      "9998              9               97                           1            7   \n",
      "9999              7               74                           0            8   \n",
      "\n",
      "      Sample Question Papers Practiced  Performance Index  \n",
      "0                                    1               91.0  \n",
      "1                                    2               65.0  \n",
      "2                                    2               45.0  \n",
      "3                                    2               36.0  \n",
      "4                                    5               66.0  \n",
      "...                                ...                ...  \n",
      "9995                                 2               23.0  \n",
      "9996                                 5               58.0  \n",
      "9997                                 5               74.0  \n",
      "9998                                 0               95.0  \n",
      "9999                                 1               64.0  \n",
      "\n",
      "[10000 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cr/2bb2z7q96qnf5txnltjfttjm0000gn/T/ipykernel_5641/3953598336.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  cleaned_df = df.replace({\"Extracurricular Activities\": {'Yes':1, 'No':0}})\n"
     ]
    }
   ],
   "source": [
    "### Replace yes with 1 and No with 0 in the 'Extracurricular Activities' column:\n",
    "cleaned_df = df.replace({\"Extracurricular Activities\": {'Yes':1, 'No':0}})\n",
    "print(cleaned_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5e153a1-93e2-4e74-8dd7-9b32bb7f5323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 4.2835425014274495\n",
      "R2 Score: 0.9884411372273585\n"
     ]
    }
   ],
   "source": [
    "### Question 1: Predict the performance index of students using Multiple Linear Regression Model:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import random\n",
    "\n",
    "async def optimize_model(df: pd.DataFrame):\n",
    "    # 1) Define the FeatureSet & LabelSet:\n",
    "    X = df.drop(axis=1, columns=[\"Performance Index\"])\n",
    "    y = df[\"Performance Index\"]\n",
    "    # 2) Call helper function to split DS into Training & Test set:\n",
    "    X_train, X_test, y_train, y_test = await split_dataset_train_test(X, y)\n",
    "    # 3) Call helper function to normalize featureset in Training & Test set:\n",
    "    X_train, X_test, scaler = await normalize_feature_set_test_df(X_train, X_test)\n",
    "    # 4) Call helper function to perform mini-batch SGD:\n",
    "    optimized_model = await perform_mini_batch_sgd(X_train, y_train)\n",
    "    # 5) Predict on the Test Set:\n",
    "    y_pred = optimized_model.predict(X_test)\n",
    "    # 6) Evaluate the model:\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R2 Score: {r2}\")\n",
    "    # 7) Return the optimized Multilinear regression model:\n",
    "    return optimized_model, scaler\n",
    "    \n",
    "### Purpose: Split DataSet into Training(80%) & Validation(20%) to ensure the model will be assessed on unseen data:\n",
    "async def split_dataset_train_test(X: pd.DataFrame, y:pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, train_size=0.8, random_state=42)\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "### Purpose: Normalize the feature set to ensure all features contributes equally to the model's performance:\n",
    "async def normalize_feature_set_test_df(X_train: pd.DataFrame, X_test: pd.DataFrame):\n",
    "    scaler = StandardScaler()\n",
    "    # 1) Calculate the mean & STD of the features in the training set\n",
    "    # 2) Standardize the features in the training set to ensure each fetures got mean=0 & STD=1\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    # 3) Apply the same feature normalization to the test set_\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test, scaler\n",
    "    \n",
    "### Purpose: Perform mini-batch SGD on training data to find W & biais which optimises the linear regression model:\n",
    "async def perform_mini_batch_sgd(X_train: pd.DataFrame, y_train: pd.DataFrame):\n",
    "    # 1) Configure the SGDRegressor object:\n",
    "    sgd = SGDRegressor(\n",
    "        loss='squared_error', # Loss (objective) function to use: Default = MSE\n",
    "        max_iter=1000, # Max nbr of pass over the training data set\n",
    "        tol=1e-3, # Tolerance for convergence} training will stop when (loss > best_loss - tol)\n",
    "        shuffle=True, # Shuffle the training dataset after each pass\n",
    "        learning_rate='adaptive', # Type of learning rate\n",
    "        eta0=0.01, # Initial learning rate\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # 2) Perform mini batch SGD:\n",
    "    batch_size=32\n",
    "    for _ in range(1000):\n",
    "        indices = np.random.choice(X_train.shape[0], batch_size, replace=False)\n",
    "        X_batch = X_train[indices]\n",
    "        y_batch = y_train.iloc[indices]\n",
    "        sgd.partial_fit(X_batch, y_batch)\n",
    "    return sgd\n",
    "\n",
    "\n",
    "optimized_model, scaler = await optimize_model(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dee95a19-4866-4175-b812-bc54be14f974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.04065178]\n"
     ]
    }
   ],
   "source": [
    "async def predict_grade_performance(model, scaler, prepTime:int, prevScores:int, extraActivities:int, sleepHours:int, nbrPracticeTest:int):\n",
    "    # 1) Create a dictionary to create a DataFrame:\n",
    "    data_points = {\n",
    "        \"Hours Studied\": [prepTime],\n",
    "        \"Previous Scores\": [prevScores],\n",
    "        \"Extracurricular Activities\": [extraActivities],\n",
    "        \"Sleep Hours\": [sleepHours],\n",
    "        \"Sample Question Papers Practiced\": [nbrPracticeTest]\n",
    "    }\n",
    "    df_input = pd.DataFrame(data=data_points)\n",
    "    # 2) Feature Normalization using the pre-trained scaler:\n",
    "    normalized_inputs = scaler.transform(df_input)\n",
    "    # 3) Predict the future performance:\n",
    "    predicted_score = model.predict(normalized_inputs)\n",
    "    return predicted_score\n",
    "\n",
    "# Predict using the same scaler\n",
    "new = await predict_grade_performance(optimized_model, scaler, 3, 50, 1, 5, 1)\n",
    "print(new)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa17119e-b6fd-42d0-bb96-4696a1463466",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------------------------------------------- PART B : Diabetes Model ------------------------------------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6181cb35-c37b-470b-92df-2a8aca5c4723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/romainkuhne/.cache/kagglehub/datasets/alexteboul/diabetes-health-indicators-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "### 1) Download the CSV DataSet:\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"alexteboul/diabetes-health-indicators-dataset\")\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32aaaf7f-af98-4197-904e-bc2195b4db43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
      "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
      "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
      "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
      "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
      "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
      "\n",
      "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
      "0                   0.0           0.0     0.0  ...            1.0   \n",
      "1                   0.0           1.0     0.0  ...            0.0   \n",
      "2                   0.0           0.0     1.0  ...            1.0   \n",
      "3                   0.0           1.0     1.0  ...            1.0   \n",
      "4                   0.0           1.0     1.0  ...            1.0   \n",
      "\n",
      "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
      "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
      "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
      "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
      "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
      "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
      "\n",
      "   Income  \n",
      "0     3.0  \n",
      "1     1.0  \n",
      "2     8.0  \n",
      "3     6.0  \n",
      "4     4.0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "### 2) Convert the CSV DataSet into a pd.DataFrame:\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_dataset(path='/Users/romainkuhne/.cache/kagglehub/datasets/alexteboul/diabetes-health-indicators-dataset/versions/1') -> pd.DataFrame:\n",
    "    try: # 1) Attempt to Get the dataset present in the path:\n",
    "        for file_name in os.listdir(path):\n",
    "            if file_name.endswith('.csv'):\n",
    "                csv_file = os.path.join(path, file_name)\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error the filepath contains no dataset: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 2) Convert the CSV file into a pd.DataSet:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    return df\n",
    "\n",
    "df = fetch_dataset()\n",
    "print(df.head(5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f9b28b-60dc-4cbd-80ca-aba9b3d22af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes_012            1.000000\n",
      "HighBP                  0.271596\n",
      "HighChol                0.209085\n",
      "CholCheck               0.067546\n",
      "BMI                     0.224379\n",
      "Smoker                  0.062914\n",
      "Stroke                  0.107179\n",
      "HeartDiseaseorAttack    0.180272\n",
      "PhysActivity           -0.121947\n",
      "Fruits                 -0.042192\n",
      "Veggies                -0.058972\n",
      "HvyAlcoholConsump      -0.057882\n",
      "AnyHealthcare           0.015410\n",
      "NoDocbcCost             0.035436\n",
      "GenHlth                 0.302587\n",
      "MentHlth                0.073507\n",
      "PhysHlth                0.176287\n",
      "DiffWalk                0.224239\n",
      "Sex                     0.031040\n",
      "Age                     0.185026\n",
      "Education              -0.130517\n",
      "Income                 -0.171483\n",
      "Name: Diabetes_012, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "### 3) Assess the Pearson correlation of label Y = Diabetes vs other columns:\n",
    "def evaluate_correlation(df: pd.DataFrame):\n",
    "    correlation_matrix = df.corr()[\"Diabetes_012\"]\n",
    "    return correlation_matrix\n",
    "\n",
    "correlation_matrix = evaluate_correlation(df)\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "918436a0-e8fd-4a80-9ff3-f41e1ec2a759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. ... 9. 4. 3.]\n",
      " [0. 0. 0. ... 7. 6. 1.]\n",
      " [0. 1. 1. ... 9. 4. 8.]\n",
      " ...\n",
      " [0. 0. 0. ... 2. 5. 2.]\n",
      " [0. 1. 0. ... 7. 5. 1.]\n",
      " [2. 1. 1. ... 9. 6. 2.]]\n"
     ]
    }
   ],
   "source": [
    "### 4) Convert the whole pd.DataFrame into a Numpy Matrix:\n",
    "import numpy as np\n",
    "def convert_df_to_matrix(df: pd.DataFrame) -> np.ndarray:\n",
    "    return df.to_numpy()\n",
    "\n",
    "matrix_dataset = convert_df_to_matrix(df)\n",
    "print(matrix_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8f2f69a-20c8-4335-bf14-d0b7832c4fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.474479363008601\n",
      "R2: 0.023580335460434365\n"
     ]
    }
   ],
   "source": [
    "### question 1) Otpimize a Multi Linear Regression Model for predicting the diagnosis of diabetes:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import random\n",
    "\n",
    "async def optimize_multi_linear_regression(dataset: np.ndarray):\n",
    "    # 1) Define Feature Set (X) & Label Set (y):\n",
    "    X = dataset[:,1:] # Feature set includes all columns from 1:\n",
    "    y = dataset[:,0] # Label set only includes column 0:\n",
    "    # 2) Call helper function to partition the dataset into training set (80%) and validation set (20%):\n",
    "    X_train, X_test, y_train, y_test = await split_dataset(X,y)\n",
    "    # 3) Call a helper function to normalize feature set in X_train & X_test:\n",
    "    X_train, X_test, scaler = await normalize_features(X_train, X_test)\n",
    "    # 4) Call helper function to tine tune the multi linear regression model using mini batch SGD:\n",
    "    optimized_multilinear_model = await perform_minibatch_sgd(X_train, y_train)\n",
    "    # 5) Predict on the validation set:\n",
    "    y_pred = optimized_multilinear_model.predict(X_test)\n",
    "    # 6) Evaluate the model:\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"R2: {r2}\")\n",
    "    # 7) Return the optimized machine learning model:\n",
    "    return optimized_multilinear_model\n",
    "\n",
    "\n",
    "### Purpose: Split the dataset into a training set (80%) and validation set (20%):\n",
    "async def split_dataset(X: np.ndarray, y: np.ndarray) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "### Purpose: Normalize Feature Set so that every feature contributes equally to the prediction:\n",
    "async def normalize_features(X_train: np.ndarray, X_test: np.ndarray):\n",
    "    scaler = StandardScaler()\n",
    "    # 1) Compute the mean & STD of each features in the train FeatureSet (X_train):\n",
    "    # 2) Apply normalization to ensure mean=0 & STD=1 so that each features contributes equally to the prediction:\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    # 3) Apply the same normalization computed previously to the FeatureSet (X_test):\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test, scaler\n",
    "\n",
    "### Purpose: Perform Mini Batch Stochastic Gradient Descend:\n",
    "async def perform_minibatch_sgd(X_train: np.ndarray, y_train: np.ndarray):\n",
    "    # 1) Configure the SGD Regressor object:\n",
    "    sgd = SGDRegressor(\n",
    "        loss='squared_error', # Sets the loss func to MSE:\n",
    "        max_iter=1000, # Sets the max nbr of iterations:\n",
    "        tol=0.001, # Sets the stopping criterion =>  training will stop when (loss > best_loss - tol):\n",
    "        shuffle=True, # Ensures the sample is shuffled back into the DataSet:\n",
    "        learning_rate='adaptive', # Determine how step size changes\n",
    "        eta0=0.01, # Sets the initial learning Rate:\n",
    "        random_state=42\n",
    "    )\n",
    "    # 2) Define Mini Batch & Perform optimization to find global minima:\n",
    "    batch_size = 32\n",
    "    for _ in range(1000):\n",
    "        indices = np.random.choice(X_train.shape[0], batch_size, replace=False)\n",
    "        X_batch = X_train[indices]\n",
    "        y_batch = y_train[indices]\n",
    "        sgd.partial_fit(X_batch, y_batch)\n",
    "    return sgd\n",
    "\n",
    "optimized_multi_linear_regression = await optimize_multi_linear_regression(matrix_dataset)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86902f7d-6f35-448f-b12d-ba3b9003434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Conclusion: The Multi Linear Regression Model isn't performing well enough !\n",
    "### This could be due to the fact that the relationship btw features and label is non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8dc0f3-64a9-48ac-85e9-19a909379783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
